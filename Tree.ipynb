{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "from skimage.morphology import square, dilation, disk\n",
    "from skimage.feature import canny\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,denoise_wavelet, estimate_sigma)\n",
    "from skimage.filters import median\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "#from Networks import *\n",
    "#from Comp2_func import *\n",
    "#from IOU import *\n",
    "\n",
    "#from datetime import datetime\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_load():\n",
    "    img_path= 'train_data/train_images/'\n",
    "    msk_path= 'train_data/train_masks/'\n",
    "    imx_bank= []\n",
    "    imy_bank= []\n",
    "    depths= []\n",
    "    depth_data= pd.read_csv('depths.csv')\n",
    "    for root, dirs, files in os.walk(img_path + '.'):  \n",
    "        for file_name in files:\n",
    "            imx= imread(img_path + file_name)\n",
    "            imy= imread(msk_path + file_name)\n",
    "            depth= depth_data['z'][depth_data['id']==file_name.split('.')[0]]\n",
    "\n",
    "            imx= rgb2gray(imx)\n",
    "            imy= imy / 65535\n",
    "            if imx.max()>0:\n",
    "                \n",
    "                #imx= (imx - np.mean(imx)) / np.std(imx)\n",
    "                size= (63, 63)\n",
    "                imx= cv2.resize(imx, size)\n",
    "                imy= cv2.resize(imy, size)\n",
    "                \n",
    "                imx_bank.append(imx)\n",
    "                imy_bank.append(imy)\n",
    "                depths.append(depth.values * np.ones((63*63, )).astype(int))  \n",
    "\n",
    "    imx_bank= np.array(imx_bank)\n",
    "    imy_bank= np.array(imy_bank)\n",
    "    depths= np.array(depths)\n",
    "    return imx_bank, imy_bank, depths\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def BP_filter(data, lowcut, highcut, fs, order, axis):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    if axis=='vertical':\n",
    "        data= np.rot90(data)\n",
    "    y = lfilter(b, a, data)\n",
    "    if axis== 'vertical':\n",
    "        y= np.rot90(y, k=1, axes=(1,0))\n",
    "    return y\n",
    "\n",
    "def BP_filter90(data, lowcut, highcut, fs, order):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    #data= np.rot90(data)\n",
    "    y = lfilter(b, a, data)\n",
    "    #y= np.rot90(y, k=1, axes=(1,0))\n",
    "    return y\n",
    "\n",
    "def bp(X, lowcut, highcut, order, axis):\n",
    "    imx_bank= []\n",
    "    for imx in X:\n",
    "        bp= BP_filter(imx, lowcut=lowcut, highcut=highcut, fs=1/0.004, order=order, axis=axis)\n",
    "        imx_bank.append(bp/1.3)\n",
    "    imx_bank= np.array(imx_bank)\n",
    "    return imx_bank\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def binary_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + (1 - dice_coef(y_true, y_pred))\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef1(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = np.sum(np.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (np.sum(np.square(y_true),-1) + np.sum(np.square(y_pred),-1) + smooth)\n",
    "\n",
    "\n",
    "# Show images\n",
    "def show_im(X, y, imp):\n",
    "    #imy= np.squeeze(y)\n",
    "    #imx_show= np.squeeze(X)\n",
    "    #imp= np.squeeze(imp, axis=[0, -1])\n",
    "\n",
    "    fig, (ax1, ax2, ax3)= plt.subplots(1, 3)\n",
    "    ax1.imshow(X)\n",
    "    ax2.imshow(y)\n",
    "    ax3.imshow(imp)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images\n",
      "(3920, 63, 63)\n"
     ]
    }
   ],
   "source": [
    "print('Loading images')\n",
    "X, y, d= im_load()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-liniar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2= X**2\n",
    "Xlog= np.log(1 + X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency BandPass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical axis\n",
    "variations= []\n",
    "low= [0.1, 2, 5, 10, 20] \n",
    "high= [7, 10, 20, 30, 40]\n",
    "order= [2, 3, 5]\n",
    "variations_prod= list(product(*[low, high, order]))\n",
    "[variations.append(x) for x in variations_prod if x[1]>x[0]]\n",
    "\n",
    "XBV= np.zeros((X.shape[0] * X.shape[1] * X.shape[2], len(variations)))\n",
    "for i, variation in enumerate(variations): \n",
    "    XBV[:, i]= bp(X, lowcut=variation[0], highcut=variation[1], order=variation[2], axis='vertical').flatten() #reshape((X.shape[0], X.shape[1] * X.shape[2] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal axis\n",
    "variations= []\n",
    "low= [0.1, 2, 5, 10, 20] \n",
    "high= [7, 10, 20, 30, 40]\n",
    "order= [2, 3, 5]\n",
    "variations_prod= list(product(*[low, high, order]))\n",
    "[variations.append(x) for x in variations_prod if x[1]>x[0]]\n",
    "\n",
    "XBH= np.zeros((X.shape[0] * X.shape[1] * X.shape[2], len(variations)))\n",
    "for i, variation in enumerate(variations): \n",
    "    XBH[:, i]= bp(X, lowcut=variation[0], highcut=variation[1], order=variation[2], axis='horizontal').flatten()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analitic Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs= 1/0.004\n",
    "analytic_signal = hilbert(X)\n",
    "\n",
    "amplitude_envelope = np.abs(analytic_signal)\n",
    "envelope_derv1= np.insert((np.diff(amplitude_envelope)), 0, 0, axis=-1)\n",
    "envelope_derv2= np.insert((np.diff(envelope_derv1)),0, 0, axis=-1)\n",
    "instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "instantaneous_frequency = np.insert((np.diff(instantaneous_phase) / (2.0*np.pi) * fs),0, 0, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in np.arange(0, len(X), 1):\n",
    "    print(n)\n",
    "    show_im(X[n], envelope_derv1[n], envelope_derv2[n])\n",
    "    show_im(amplitude_envelope[n], instantaneous_phase[n], instantaneous_frequency[n])\n",
    "    show_im(y[n], X2[n], Xlog[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_f= np.expand_dims(X.flatten(), axis=1)\n",
    "X2_f= np.expand_dims(X2.flatten(), axis=1)\n",
    "Xlog_f= np.expand_dims(Xlog.flatten(), axis=1)\n",
    "d_f= np.expand_dims(d.flatten(), axis=1)\n",
    "ae_f=  np.expand_dims(amplitude_envelope.flatten(), axis=1)\n",
    "aed1_f=  np.expand_dims(envelope_derv1.flatten(), axis=1)\n",
    "aed2_f=  np.expand_dims(envelope_derv2.flatten(), axis=1)\n",
    "ip_f=  np.expand_dims(instantaneous_phase.flatten(), axis=1)\n",
    "if_f=  np.expand_dims(instantaneous_frequency.flatten(), axis=1)\n",
    "y_f= (y.flatten()).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "* Need to merge test data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.96838581e-01, 1.75138007e-03, 1.22037141e-03, 1.45372145e-04,\n",
       "       1.97878556e-05, 1.44052465e-05, 1.00932509e-05, 8.57259470e-09])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1 = PCA()\n",
    "Xpc= pca1.fit_transform(np.hstack((X_f, X2_f, Xlog_f, ae_f, aed1_f, aed2_f, ip_f, if_f)))\n",
    "pca1.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpc1= Xpc[:, 0].reshape(-1, 63, 63)\n",
    "Xpc2= Xpc[:, 1].reshape(-1, 63, 63)\n",
    "Xpc3= Xpc[:, 2].reshape(-1, 63, 63)\n",
    "Xpc4= Xpc[:, 3].reshape(-1, 63, 63)\n",
    "Xpc5= Xpc[:, 4].reshape(-1, 63, 63)\n",
    "Xpc6= Xpc[:, 5].reshape(-1, 63, 63)\n",
    "Xpc7= Xpc[:, 6].reshape(-1, 63, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=15\n",
    "show_im(X[n], Xpc1[n], Xpc2[n])\n",
    "show_im(Xpc3[n], Xpc4[n], Xpc5[n])\n",
    "show_im(Xpc6[n], Xpc7[n], y[n])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.64064524e-01, 2.40532070e-01, 1.64632955e-01, 9.59964170e-02,\n",
       "       4.73215540e-02, 3.42361093e-02, 1.91960203e-02, 1.31947027e-02,\n",
       "       8.42757475e-03, 4.59525830e-03, 4.10732153e-03, 2.23285485e-03,\n",
       "       8.38500946e-04, 3.27341237e-04, 1.91655353e-04, 7.40147537e-05,\n",
       "       2.01859405e-05, 7.14954709e-06, 2.58553819e-06, 6.23720955e-07,\n",
       "       4.91784993e-07, 4.43825111e-08, 3.76721871e-08, 6.34564780e-09,\n",
       "       6.00475524e-10, 4.47604766e-10, 9.58191042e-12, 4.09385192e-12,\n",
       "       4.66921237e-13, 1.72512401e-13, 8.12914215e-14, 1.85251789e-14,\n",
       "       4.74595546e-15, 3.80577121e-15, 2.04739655e-15, 1.50878398e-15,\n",
       "       5.37691318e-17, 3.85673004e-17, 2.13692108e-17, 3.35165451e-18,\n",
       "       9.41897011e-19, 4.11390882e-19, 2.53507034e-19, 1.56826383e-19,\n",
       "       1.03711440e-19, 1.82185621e-20, 6.00652884e-21, 4.34323899e-21,\n",
       "       1.82294074e-21, 1.65292595e-22, 1.47528436e-22, 7.56926201e-23,\n",
       "       3.29703785e-23, 3.91658517e-24, 1.29968356e-24, 6.97815071e-25,\n",
       "       1.19269045e-25, 9.73368357e-26, 3.98688785e-26, 3.34670365e-27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2 = PCA()\n",
    "XBVpc= pca2.fit_transform(XBV)\n",
    "pca2.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPVpc1= XBVpc[:, 0].reshape(-1, 63, 63)\n",
    "BPVpc2= XBVpc[:, 1].reshape(-1, 63, 63)\n",
    "BPVpc3= XBVpc[:, 2].reshape(-1, 63, 63)\n",
    "BPVpc4= XBVpc[:, 3].reshape(-1, 63, 63)\n",
    "BPVpc5= XBVpc[:, 4].reshape(-1, 63, 63)\n",
    "BPVpc6= XBVpc[:, 5].reshape(-1, 63, 63)\n",
    "BPVpc7= XBVpc[:, 6].reshape(-1, 63, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=15\n",
    "show_im(X[n], BPVpc1[n], BPVpc2[n])\n",
    "show_im(BPVpc3[n], BPVpc4[n], BPVpc5[n])\n",
    "show_im(BPVpc6[n], BPVpc7[n], y[n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.71556074e-01, 2.74417926e-01, 1.48545107e-01, 8.61069293e-02,\n",
       "       4.47241329e-02, 2.80412702e-02, 1.83580507e-02, 1.13102744e-02,\n",
       "       6.46218315e-03, 3.96266621e-03, 3.49337644e-03, 1.82044285e-03,\n",
       "       6.45422972e-04, 3.13963961e-04, 1.55251922e-04, 6.15203861e-05,\n",
       "       1.61481228e-05, 5.91883100e-06, 2.33154876e-06, 5.05696676e-07,\n",
       "       4.24145371e-07, 3.86237040e-08, 3.32192985e-08, 5.91143918e-09,\n",
       "       5.56718916e-10, 3.87860278e-10, 8.40377556e-12, 3.86328252e-12,\n",
       "       4.27199718e-13, 1.78875224e-13, 8.40970854e-14, 1.72620012e-14,\n",
       "       4.91323973e-15, 3.58174477e-15, 2.06428622e-15, 1.56772558e-15,\n",
       "       5.17241887e-17, 3.81996220e-17, 2.17399882e-17, 3.17245332e-18,\n",
       "       9.82043565e-19, 4.19881360e-19, 2.53946479e-19, 1.51041132e-19,\n",
       "       1.04645147e-19, 1.76667840e-20, 6.19361393e-21, 4.20081030e-21,\n",
       "       1.87765773e-21, 1.65154351e-22, 1.45442398e-22, 7.76917673e-23,\n",
       "       3.40342114e-23, 3.81183161e-24, 1.28804153e-24, 6.99574299e-25,\n",
       "       1.28493492e-25, 9.99741537e-26, 4.31766153e-26, 3.60205260e-27])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca3 = PCA()\n",
    "XBHpc= pca3.fit_transform(XBH)\n",
    "pca3.explained_variance_ratio_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "enc = KBinsDiscretizer(n_bins=100, encode='ordinal')\n",
    "X_binned = enc.fit_transform(Xpc[:, 0].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for q in range(100):\n",
    "    #z= X_binned[X_binned==q]\n",
    "    z1= y_f.reshape(-1,1)[X_binned==q]\n",
    "    plt.hist(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne5= TSNE(n_components=3, perplexity= 5, learning_rate= 300, \n",
    "           n_iter= 250, n_iter_without_progress= 5, \n",
    "           random_state= 0, verbose= 5)\n",
    "tsne60= TSNE(n_components=3, perplexity= 60, learning_rate= 300, \n",
    "           n_iter= 1000, n_iter_without_progress= 5, \n",
    "           random_state= 0, verbose= 5)\n",
    "tsne100= TSNE(n_components=3, perplexity= 100, learning_rate= 300, \n",
    "           n_iter= 250, n_iter_without_progress= 5, \n",
    "           random_state= 0, verbose= 5)\n",
    "\n",
    "\n",
    "#data= np.hstack((d_f[4*63*63:7*63*63, :], Xpc[4*63*63:7*63*63, :]))\n",
    "\n",
    "Xsne5= tsne5.fit_transform(data)\n",
    "#Xsne60= tsne60.fit_transform(data)\n",
    "#Xsne100= tsne100.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.scatter(Xsne5[:, 1], Xsne5[:, 2], s= 0.7, c=y_f[4*63*63:7*63*63]);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.scatter(Xsne100[:, 0], Xsne100[:, 1], s= 0.7, c=y_f[4*63*63:7*63*63]);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.scatter(Xsne30[:, 1], Xsne30[:, 2], s= 0.7, c=y_f[4*63*63:7*63*63]);plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15558480, 19)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= np.hstack((d_f, Xpc))\n",
    "scaler = MinMaxScaler()\n",
    "X_modeling= scaler.fit_transform(data)\n",
    "\n",
    "knn_model= KNeighborsRegressor(n_neighbors=20, n_jobs=12)\n",
    "\n",
    "#ynn= y_f[4*63*63:7*63*63]\n",
    "knn_model.fit(data, y_f)\n",
    "dist, _= knn_model.kneighbors(data)\n",
    "dist= dist[:, 1:]\n",
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15558480, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stas= []\n",
    "for w in [3, 9, 19]:\n",
    "    Stas.append(dist[:, :w].mean(axis=1))\n",
    "    Stas.append(dist[:, :w].std(axis=1))\n",
    "Stas= np.array(Stas).T\n",
    "Stas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_stacked= np.hstack((X_f, X2_f, Xlog_f, d_f, XBV, XBH, ae_f, aed1_f, aed2_f, ip_f, if_f))\n",
    "\n",
    "X_modeling= np.hstack((d_f, Xpc, XBVpc, XBHpc))#, Stas\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_modeling= scaler.fit_transform(X_modeling)\n",
    "#print(X_modeling.max(), X_modeling.shape)\n",
    "\n",
    "Xpc= scaler.fit_transform(Xpc)\n",
    "XBVpc= scaler.fit_transform(XBVpc)\n",
    "XBHpc= scaler.fit_transform(XBHpc)\n",
    "#Stas= scaler.fit_transform(Stas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "level1= []\n",
    "\n",
    "lgb_params= {'feature_fraction': 0.7,'metric': 'rmse', 'nthread':12, 'min_data_in_leaf': 2**7, \n",
    "                  'bagging_fraction': 0.7, 'learning_rate': 0.05, 'objective': 'rmse',\n",
    "                  'bagging_seed': 2**5, 'num_leaves': 2**11,'bagging_freq':1}\n",
    "\n",
    "for level1_X in [X_modeling[:, :61], X_modeling[:, :21], Xpc, XBVpc, XBHpc]:#, Stas\n",
    "    \n",
    "    #print('CAT')\n",
    "    #level1_CATmodel = CatBoostRegressor(iterations=200, learning_rate=0.05, \n",
    "     #                                   min_data_in_leaf= 2**7, depth=5, \n",
    "      #                                  random_seed= 0, verbose= 50)\n",
    "    #level1_CATmodel.fit(level1_X, y_f)\n",
    "    #level1_pCAT= level1_CATmodel.predict(level1_X)\n",
    "    #level1.append(level1_pCAT)\n",
    "\n",
    "    print('LGB')\n",
    "    level1_LGBmodel = lgb.train(lgb_params, lgb.Dataset(level1_X, label=y_f), 50)\n",
    "    p1= level1_LGBmodel.predict(level1_X)\n",
    "    error= y_f-p + 1\n",
    "    \n",
    "    print('LGB_error')\n",
    "    lgb_params= {'feature_fraction': 0.7,'metric': 'rmse', 'nthread':12, 'min_data_in_leaf': 2**7, \n",
    "                  'bagging_fraction': 0.7, 'learning_rate': 0.05, 'objective': 'rmse',\n",
    "                  'bagging_seed': 2**5, 'num_leaves': 2**11,'bagging_freq':1,'verbosity': 50}\n",
    "    \n",
    "    level1_LGBmodel = lgb.train(lgb_params, lgb.Dataset(level1_X, label=y_f, weight=error), 300)\n",
    "    p= level1_LGBmodel.predict(level1_X)\n",
    "    error1= y_f-p1\n",
    "    \n",
    "    print('LGB_error1')\n",
    "    level1_LGBmodel = lgb.train(lgb_params, lgb.Dataset(level1_X, label=error1), 30)\n",
    "    p2= level1_LGBmodel.predict(level1_X)\n",
    "    \n",
    "    level1.append(p1 + p2)\n",
    "    ax = lgb.plot_importance(level1_LGBmodel, figsize=(12, 30));plt.show()\n",
    "    \n",
    "    #print('BR')\n",
    "    #level1_X= np.hstack((level1_X, np.ones((level1_X.shape[0], 1))))\n",
    "    #level1_BRmodel= BayesianRidge()\n",
    "    #level1_BRmodel.fit(level1_X, y_f)\n",
    "    #level1_pBR= level1_BRmodel.predict(level1_X)\n",
    "    #level1.append(level1_pBR)\n",
    "    \n",
    "level1= np.array(level1).T \n",
    "level1.max(axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15558480,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_f.shape\n",
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level= level1\n",
    "for col in range(level.shape[1]):\n",
    "    dice= []\n",
    "    thresholds= np.arange(0.1, level[:, col].max(), 0.01)\n",
    "    for threshold in thresholds:\n",
    "        p_test= np.zeros((level.shape[0], 1))\n",
    "\n",
    "        p_test[level[:, col] > threshold]= 1\n",
    "        p_test= p_test.astype(np.float32)\n",
    "        y_true= y_f.astype(np.float32)\n",
    "\n",
    "        dice.append(dice_coef1(y_true, p_test.squeeze()))\n",
    "    plt.plot(thresholds, dice)\n",
    "    max_dice= np.array(dice).max()\n",
    "    best_th= thresholds[np.argmax(np.array(dice))]\n",
    "    print('max dice is ' + str(max_dice) + ' at threshold ' + str(best_th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_level2= level1\n",
    "X_level2.shape\n",
    "scaler1 = MinMaxScaler()\n",
    "X_level2= scaler1.fit_transform(X_level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "level2= []\n",
    "\n",
    "print('BR')\n",
    "level2_BRmodel= BayesianRidge()\n",
    "level2_BRmodel.fit(X_level2, y_f)\n",
    "level2_pBR= level2_BRmodel.predict(X_level2)\n",
    "print(level2_pBR.max(), level2_BRmodel.coef_)\n",
    "level2.append(level2_pBR)\n",
    "\n",
    "#print('SVR')\n",
    "#level2_SVRmodel= SVR(kernel= 'linear', gamma='scale', C=1.0, epsilon=0.2, max_iter= 300)\n",
    "#level2_SVRmodel.fit(X_level2, y_f)\n",
    "#level2_pSVR= level2_SVRmodel.predict(X_level2)\n",
    "#level2.append(level2_pSVR)\n",
    "\n",
    "print('KNN')\n",
    "level2_KNNmodel= KNeighborsRegressor(n_neighbors=3, n_jobs=12)\n",
    "level2_KNNmodel.fit(X_level2, y_f)\n",
    "level2_pKNN= level2_KNNmodel.predict(X_level2)\n",
    "level2.append(level2_pKNN)\n",
    "\n",
    "print('LGB')\n",
    "level2_LGBmodel = lgb.train(lgb_params, lgb.Dataset(X_level2, label=y_f), 500)\n",
    "level2_pLGB= level2_LGBmodel.predict(X_level2)\n",
    "ax = lgb.plot_importance(level2_LGBmodel, figsize=(12, 30));plt.show()\n",
    "\n",
    "\n",
    "#print('Ada')\n",
    "#level2_Adamodel = AdaBoostRegressor(DecisionTreeRegressor(max_depth= 3, \n",
    " #                                                         min_samples_leaf= 2**7), \n",
    "  #                                  learning_rate=0.1, \n",
    "   #                                 random_state=0, \n",
    "    #                                n_estimators=2)\n",
    "\n",
    "#level2_Adamodel.fit(level2_X, y_f)\n",
    "#level2_pAda= level2_Adamodel.predict(level2_X)\n",
    "#level2.append(level2_pAda) \n",
    "\n",
    "#print('Ada')\n",
    "#level2_Adamodel = AdaBoostRegressor(base_estimator= GradientBoostingRegressor(subsample= 0.7, \n",
    " #                                                                             min_samples_leaf= 2**7, \n",
    "  #                                                                            max_depth=5), \n",
    "   #                                 learning_rate=0.1, \n",
    "    #                                random_state=0, \n",
    "     #                               n_estimators=2)\n",
    "\n",
    "#level2_Adamodel.fit(level2_X, y_f)\n",
    "#level2_pAda= level2_Adamodel.predict(level2_X)\n",
    "#level2.append(level2_pAda) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "level2.append(level2_pLGB)\n",
    "level2= np.array(level2).T \n",
    "level2.max(axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "level= level2\n",
    "for col in range(level.shape[1]): \n",
    "    dice= []\n",
    "    thresholds= np.arange(0.1, level[:, col].max(), 0.01)\n",
    "    for threshold in thresholds:\n",
    "        p_test= np.zeros((level.shape[0], 1))\n",
    "\n",
    "        p_test[level[:, col] > threshold]= 1\n",
    "        p_test= p_test.astype(np.float32)\n",
    "        y_true= y_f.astype(np.float32)\n",
    "\n",
    "        dice.append(dice_coef1(y_true, p_test.squeeze()))\n",
    "    plt.plot(thresholds, dice)\n",
    "    max_dice= np.array(dice).max()\n",
    "    best_th= thresholds[np.argmax(np.array(dice))]\n",
    "    print('max dice is ' + str(max_dice) + 'at threshold ' + str(best_th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler()\n",
    "X_level3= scaler2.fit_transform(level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1788653189180875 [-0.40211719  0.95485541  0.39739217]\n"
     ]
    }
   ],
   "source": [
    "level3_BRmodel= BayesianRidge()\n",
    "level3_BRmodel.fit(X_level3, y_f)\n",
    "level3_pBR= level3_BRmodel.predict(X_level3)\n",
    "print(level3_pBR.max(), level3_BRmodel.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVR')\n",
    "level3_SVRmodel= SVR(kernel= 'liniar', gamma='scale', C=1.0, epsilon=0.2, max_iter= 1000)\n",
    "level3_SVRmodel.fit(X_level3, y_f)\n",
    "level3_pSVR= level3_SVRmodel.predict(X_level3)\n",
    "#level3.append(level3_pSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN')\n",
    "level3_KNNmodel= KNeighborsRegressor(n_neighbors=3, n_jobs=12)\n",
    "level3_KNNmodel.fit(X_level3, y_f)\n",
    "level3_pKNN= level3_KNNmodel.predict(X_level3)\n",
    "level3.append(level3_pKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "level= level3_pBR\n",
    "\n",
    "dice= []\n",
    "thresholds= np.arange(0.1, level.max(), 0.01)\n",
    "for threshold in thresholds:\n",
    "    p_test= np.zeros((level.shape))\n",
    "\n",
    "    p_test[level > threshold]= 1\n",
    "    p_test= p_test.astype(np.float32)\n",
    "    y_true= y_f.astype(np.float32)\n",
    "\n",
    "    dice.append(dice_coef1(y_true, p_test.squeeze()))\n",
    "plt.plot(thresholds, dice)\n",
    "max_dice= np.array(dice).max()\n",
    "best_th= thresholds[np.argmax(np.array(dice))]\n",
    "print('max dice is ' + str(max_dice) + 'at threshold ' + str(best_th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_final= np.zeros((level3_pBR.shape))\n",
    "p_final[level3_pBR > best_th]= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp= p_final.reshape((-1, 63, 63))\n",
    "y_c= y_true.reshape((-1, 63, 63))\n",
    "\n",
    "for i in np.arange(0, len(X), 5):\n",
    "    print(i)\n",
    "    show_im(X[i], y_c[i], imp[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irosion/Dilation/AutoEncoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
